{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>County Centroid</th>\n",
       "      <th>year</th>\n",
       "      <th>CDC Week</th>\n",
       "      <th>Week Ending Date</th>\n",
       "      <th>Count</th>\n",
       "      <th>Disease_INFLUENZA_A</th>\n",
       "      <th>Disease_INFLUENZA_B</th>\n",
       "      <th>Disease_INFLUENZA_UNSPECIFIED</th>\n",
       "      <th>...</th>\n",
       "      <th>cough</th>\n",
       "      <th>soreThroat</th>\n",
       "      <th>Target</th>\n",
       "      <th>VaxRate</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>SNOWDepth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index_Count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALBANY</td>\n",
       "      <td>36001</td>\n",
       "      <td>(42.5882713, -73.9740136)</td>\n",
       "      <td>2009</td>\n",
       "      <td>40</td>\n",
       "      <td>10/10/2009</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112639</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.642857</td>\n",
       "      <td>61.285714</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALBANY</td>\n",
       "      <td>36001</td>\n",
       "      <td>(42.5882713, -73.9740136)</td>\n",
       "      <td>2009</td>\n",
       "      <td>41</td>\n",
       "      <td>10/17/2009</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083486</td>\n",
       "      <td>0.067525</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALBANY</td>\n",
       "      <td>36001</td>\n",
       "      <td>(42.5882713, -73.9740136)</td>\n",
       "      <td>2009</td>\n",
       "      <td>42</td>\n",
       "      <td>10/24/2009</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156241</td>\n",
       "      <td>0.091104</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.071429</td>\n",
       "      <td>48.285714</td>\n",
       "      <td>29.857143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALBANY</td>\n",
       "      <td>36001</td>\n",
       "      <td>(42.5882713, -73.9740136)</td>\n",
       "      <td>2009</td>\n",
       "      <td>43</td>\n",
       "      <td>10/31/2009</td>\n",
       "      <td>87</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214376</td>\n",
       "      <td>0.078840</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>58.857143</td>\n",
       "      <td>37.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALBANY</td>\n",
       "      <td>36001</td>\n",
       "      <td>(42.5882713, -73.9740136)</td>\n",
       "      <td>2009</td>\n",
       "      <td>44</td>\n",
       "      <td>11/07/2009</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246317</td>\n",
       "      <td>0.125195</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.857143</td>\n",
       "      <td>56.285714</td>\n",
       "      <td>41.428571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             County   FIPS            County Centroid  year  CDC Week  \\\n",
       "Index_Count                                                             \n",
       "0            ALBANY  36001  (42.5882713, -73.9740136)  2009        40   \n",
       "1            ALBANY  36001  (42.5882713, -73.9740136)  2009        41   \n",
       "2            ALBANY  36001  (42.5882713, -73.9740136)  2009        42   \n",
       "3            ALBANY  36001  (42.5882713, -73.9740136)  2009        43   \n",
       "4            ALBANY  36001  (42.5882713, -73.9740136)  2009        44   \n",
       "\n",
       "            Week Ending Date  Count  Disease_INFLUENZA_A  Disease_INFLUENZA_B  \\\n",
       "Index_Count                                                                     \n",
       "0                 10/10/2009      4                    4                    0   \n",
       "1                 10/17/2009     11                   11                    0   \n",
       "2                 10/24/2009     27                   27                    0   \n",
       "3                 10/31/2009     87                   86                    1   \n",
       "4                 11/07/2009     77                   76                    1   \n",
       "\n",
       "             Disease_INFLUENZA_UNSPECIFIED    ...         cough soreThroat  \\\n",
       "Index_Count                                   ...                            \n",
       "0                                        0    ...      0.112639   0.087600   \n",
       "1                                        0    ...      0.083486   0.067525   \n",
       "2                                        0    ...      0.156241   0.091104   \n",
       "3                                        0    ...      0.214376   0.078840   \n",
       "4                                        0    ...      0.246317   0.125195   \n",
       "\n",
       "            Target VaxRate      PRCP  SNOW       TAVG       TMAX       TMIN  \\\n",
       "Index_Count                                                                   \n",
       "0             27.0     NaN  0.058333   0.0  54.642857  61.285714  48.000000   \n",
       "1             87.0     NaN  0.058571   0.0  52.000000  60.000000  44.000000   \n",
       "2             77.0     NaN  0.041667   0.0  39.071429  48.285714  29.857143   \n",
       "3             61.0     NaN  0.303333   0.0  48.000000  58.857143  37.142857   \n",
       "4             29.0     NaN  0.212857   0.0  48.857143  56.285714  41.428571   \n",
       "\n",
       "             SNOWDepth  \n",
       "Index_Count             \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/master.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psyrbin/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "# for column in ['Population', 'UnempRate', 'GDP', 'GDP_change']:\n",
    "#     data[column] = data[column].replace('-',np.nan).astype('float64')\n",
    "# data = data.drop(['County', 'FIPS', 'County Centroid'],axis=1)\n",
    "# data = data.drop('Week Ending Date',axis=1)\n",
    "data = data.fillna(data.mean())\n",
    "# Y = data['Target'].fillna(data['Target'].mean())/ data['Target'].mean()\n",
    "# X = normalize(data.drop('Target',axis=1),axis=0)\n",
    "Y = data['Target'].fillna(data['Target'].mean())\n",
    "# X = data.drop(['Target'],axis=1)\n",
    "X = data[['year','CDC Week','Count', 'flu', 'cough']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.8, random_state = 585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train.shape[1], activation=None))\n",
    "model.add(Dense(128, activation=None))\n",
    "model.add(Dense(32, activation=None))\n",
    "model.add(Dense(1, activation=None))\n",
    "opt = keras.optimizers.Adadelta(learning_rate=0.008, rho=0.6)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/550\n",
      "16064/16064 [==============================] - 1s 41us/step - loss: 13766.3042 - mse: 13766.3047 - mae: 80.9366\n",
      "Epoch 2/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 12180.7434 - mse: 12180.7432 - mae: 70.4061\n",
      "Epoch 3/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 10666.3932 - mse: 10666.3936 - mae: 58.7763\n",
      "Epoch 4/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 9439.3518 - mse: 9439.3516 - mae: 47.2721\n",
      "Epoch 5/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 8473.0722 - mse: 8473.0713 - mae: 35.7764\n",
      "Epoch 6/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 7831.0246 - mse: 7831.0249 - mae: 26.5668\n",
      "Epoch 7/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 7451.4477 - mse: 7451.4478 - mae: 27.0213\n",
      "Epoch 8/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 7284.9077 - mse: 7284.9072 - mae: 29.1991\n",
      "Epoch 9/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 7184.3349 - mse: 7184.3345 - mae: 31.5556\n",
      "Epoch 10/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 7106.7759 - mse: 7106.7759 - mae: 35.0900\n",
      "Epoch 11/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 7075.1111 - mse: 7075.1113 - mae: 33.9121\n",
      "Epoch 12/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 7042.9015 - mse: 7042.9014 - mae: 33.3704\n",
      "Epoch 13/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6974.3221 - mse: 6974.3218 - mae: 35.2132\n",
      "Epoch 14/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6942.5399 - mse: 6942.5400 - mae: 32.9935\n",
      "Epoch 15/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6893.2938 - mse: 6893.2939 - mae: 35.7366\n",
      "Epoch 16/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6848.7137 - mse: 6848.7139 - mae: 36.2011\n",
      "Epoch 17/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6808.6382 - mse: 6808.6387 - mae: 36.1170\n",
      "Epoch 18/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6776.9877 - mse: 6776.9883 - mae: 37.1768\n",
      "Epoch 19/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 6704.9332 - mse: 6704.9326 - mae: 34.6238\n",
      "Epoch 20/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6668.6836 - mse: 6668.6831 - mae: 34.5830\n",
      "Epoch 21/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6626.7663 - mse: 6626.7666 - mae: 32.5735\n",
      "Epoch 22/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6600.6217 - mse: 6600.6216 - mae: 31.8937\n",
      "Epoch 23/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6550.6143 - mse: 6550.6143 - mae: 35.4257\n",
      "Epoch 24/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6500.6823 - mse: 6500.6821 - mae: 33.1657\n",
      "Epoch 25/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6473.1396 - mse: 6473.1396 - mae: 31.5394\n",
      "Epoch 26/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6422.0255 - mse: 6422.0249 - mae: 32.6745\n",
      "Epoch 27/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6367.6357 - mse: 6367.6353 - mae: 32.1983\n",
      "Epoch 28/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6320.4117 - mse: 6320.4111 - mae: 33.8242\n",
      "Epoch 29/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6287.3378 - mse: 6287.3379 - mae: 30.6949\n",
      "Epoch 30/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6234.3826 - mse: 6234.3823 - mae: 34.0236\n",
      "Epoch 31/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6180.9316 - mse: 6180.9316 - mae: 33.6307\n",
      "Epoch 32/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6133.0401 - mse: 6133.0405 - mae: 34.3396\n",
      "Epoch 33/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 6072.8855 - mse: 6072.8848 - mae: 32.6352\n",
      "Epoch 34/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 6019.9780 - mse: 6019.9775 - mae: 31.7981\n",
      "Epoch 35/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5981.1132 - mse: 5981.1133 - mae: 33.9345\n",
      "Epoch 36/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5939.2330 - mse: 5939.2329 - mae: 31.9566\n",
      "Epoch 37/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5903.1150 - mse: 5903.1152 - mae: 30.6966\n",
      "Epoch 38/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5878.3831 - mse: 5878.3833 - mae: 30.0272\n",
      "Epoch 39/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5840.4278 - mse: 5840.4277 - mae: 30.0020\n",
      "Epoch 40/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5817.7423 - mse: 5817.7422 - mae: 29.3269\n",
      "Epoch 41/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5791.0047 - mse: 5791.0049 - mae: 28.7183\n",
      "Epoch 42/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5738.2098 - mse: 5738.2095 - mae: 31.7352\n",
      "Epoch 43/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5691.1254 - mse: 5691.1255 - mae: 31.5691\n",
      "Epoch 44/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5657.7274 - mse: 5657.7271 - mae: 29.5385\n",
      "Epoch 45/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5623.8549 - mse: 5623.8550 - mae: 29.4091\n",
      "Epoch 46/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5582.2271 - mse: 5582.2271 - mae: 29.9775\n",
      "Epoch 47/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5544.4732 - mse: 5544.4731 - mae: 32.0034\n",
      "Epoch 48/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5516.3369 - mse: 5516.3369 - mae: 32.8422\n",
      "Epoch 49/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5468.1984 - mse: 5468.1982 - mae: 28.5324\n",
      "Epoch 50/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5440.6694 - mse: 5440.6694 - mae: 28.2872\n",
      "Epoch 51/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5414.3763 - mse: 5414.3765 - mae: 27.8851\n",
      "Epoch 52/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5366.7374 - mse: 5366.7378 - mae: 31.6762\n",
      "Epoch 53/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5336.3073 - mse: 5336.3076 - mae: 29.8908\n",
      "Epoch 54/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5326.2752 - mse: 5326.2754 - mae: 27.9353\n",
      "Epoch 55/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5302.1800 - mse: 5302.1797 - mae: 28.3680\n",
      "Epoch 56/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5287.0633 - mse: 5287.0635 - mae: 27.6125\n",
      "Epoch 57/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5267.1262 - mse: 5267.1260 - mae: 27.4427\n",
      "Epoch 58/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5225.3354 - mse: 5225.3350 - mae: 29.2641\n",
      "Epoch 59/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 5189.1315 - mse: 5189.1313 - mae: 29.3487\n",
      "Epoch 60/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 5157.6299 - mse: 5157.6299 - mae: 31.0676\n",
      "Epoch 61/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 5120.1378 - mse: 5120.1372 - mae: 28.1025\n",
      "Epoch 62/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 5099.1066 - mse: 5099.1064 - mae: 30.5609\n",
      "Epoch 63/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5069.0890 - mse: 5069.0894 - mae: 27.6342\n",
      "Epoch 64/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 5032.1794 - mse: 5032.1797 - mae: 28.0671\n",
      "Epoch 65/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 4998.3884 - mse: 4998.3887 - mae: 29.6756\n",
      "Epoch 66/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4976.4234 - mse: 4976.4233 - mae: 26.6396\n",
      "Epoch 67/550\n",
      "16064/16064 [==============================] - 0s 5us/step - loss: 4949.5032 - mse: 4949.5029 - mae: 26.6154\n",
      "Epoch 68/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16064/16064 [==============================] - 0s 4us/step - loss: 4900.4554 - mse: 4900.4551 - mae: 28.0128\n",
      "Epoch 69/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4871.3797 - mse: 4871.3794 - mae: 29.3164\n",
      "Epoch 70/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4844.7372 - mse: 4844.7378 - mae: 26.6695\n",
      "Epoch 71/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4820.2185 - mse: 4820.2188 - mae: 26.1375\n",
      "Epoch 72/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4770.4673 - mse: 4770.4673 - mae: 27.6501\n",
      "Epoch 73/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4746.8563 - mse: 4746.8560 - mae: 30.2259\n",
      "Epoch 74/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4699.4325 - mse: 4699.4326 - mae: 28.0187\n",
      "Epoch 75/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4678.2808 - mse: 4678.2808 - mae: 25.8601\n",
      "Epoch 76/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4655.3001 - mse: 4655.3003 - mae: 29.5872\n",
      "Epoch 77/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4627.8592 - mse: 4627.8589 - mae: 28.1379\n",
      "Epoch 78/550\n",
      "16064/16064 [==============================] - 0s 4us/step - loss: 4613.1023 - mse: 4613.1021 - mae: 28.7625\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=550, batch_size=8000)\n",
    "metrics_train = model.evaluate(X_train, Y_train)\n",
    "metrics_test = model.evaluate(X_test, Y_test)\n",
    "print(metrics_train, '\\n', metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "LR: R2 =  0.677650568300046  MSE =  2369.306183728299  MAE =  15.866425969444528\n",
      "NN: R2 =  0.6726416494573171  MSE =  2406.122325532195  MAE =  16.541733039932307\n",
      "Test:\n",
      "LR: R2 =  0.6995912655021594  MSE =  2850.6821457299893  MAE =  16.73678735967538\n",
      "NN: R2 =  0.6890800832271791  MSE =  2950.4263815022546  MAE =  17.428853913737743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "lr = LinearRegression().fit(X_train, Y_train)\n",
    "train_pred_lr = lr.predict(X_train)\n",
    "test_pred_lr = lr.predict(X_test)\n",
    "train_pred_NN = model.predict(X_train)\n",
    "test_pred_NN = model.predict(X_test)\n",
    "print('Train:')\n",
    "print('LR: R2 = ', r2_score(Y_train, train_pred_lr), ' MSE = ', mean_squared_error(Y_train, train_pred_lr), ' MAE = ', mean_absolute_error(Y_train, train_pred_lr))\n",
    "print('NN: R2 = ', r2_score(Y_train, train_pred_NN), ' MSE = ', mean_squared_error(Y_train, train_pred_NN), ' MAE = ', mean_absolute_error(Y_train, train_pred_NN))\n",
    "\n",
    "\n",
    "print('Test:')\n",
    "print('LR: R2 = ', r2_score(Y_test, test_pred_lr), ' MSE = ', mean_squared_error(Y_test, test_pred_lr), ' MAE = ', mean_absolute_error(Y_test, test_pred_lr))\n",
    "print('NN: R2 = ', r2_score(Y_test, test_pred_NN), ' MSE = ', mean_squared_error(Y_test, test_pred_NN), ' MAE = ', mean_absolute_error(Y_test, test_pred_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6336531506116924 2850.6821457299893 16.73678735967538\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "print(r2_score(Y_pred, Y_test), mean_squared_error(Y_pred, Y_test), mean_absolute_error(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
